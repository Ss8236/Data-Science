{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "vncDsAP0Gaoa",
        "w6K7xa23Elo4",
        "mDgbUHAGgjLW",
        "35m5QtbWiB9F",
        "MSa1f5Uengrz",
        "K5QZ13OEpz2H",
        "lQ7QKXXCp7Bj",
        "448CDAPjqfQr",
        "t6dVpIINYklI",
        "ijmpgYnKYklI",
        "-JiQyfWJYklI",
        "EM7whBJCYoAo",
        "fge-S5ZAYoAp",
        "85gYPyotYoAp",
        "RoGjAbkUYoAp",
        "4Of9eVA-YrdM",
        "iky9q4vBYrdO",
        "F6T5p64dYrdO",
        "y-Ehk30pYrdP",
        "bamQiAODYuh1",
        "QHF8YVU7Yuh3",
        "GwzvFGzlYuh3",
        "qYpmQ266Yuh3",
        "OH-pJp9IphqM",
        "bbFf2-_FphqN",
        "_ouA3fa0phqN",
        "Seke61FWphqN",
        "t27r6nlMphqO",
        "r2jJGEOYphqO",
        "b0JNsNcRphqO",
        "BZR9WyysphqO",
        "jj7wYXLtphqO",
        "eZrbJ2SmphqO",
        "rFu4xreNphqO",
        "YJ55k-q6phqO",
        "gCFgpxoyphqP",
        "OVtJsKN_phqQ",
        "lssrdh5qphqQ",
        "U2RJ9gkRphqQ",
        "1M8mcRywphqQ",
        "tgIPom80phqQ",
        "JMzcOPDDphqR",
        "x-EpHcCOp1ci",
        "X_VqEhTip1ck",
        "8zGJKyg5p1ck",
        "PVzmfK_Ep1ck",
        "n3dbpmDWp1ck",
        "ylSl6qgtp1ck",
        "ZWILFDl5p1ck",
        "M7G43BXep1ck",
        "Ag9LCva-p1cl",
        "E6MkPsBcp1cl",
        "2cELzS2fp1cl",
        "3MPXvC8up1cl",
        "NC_X3p0fY2L0",
        "UV0SzAkaZNRQ",
        "YPEH6qLeZNRQ",
        "q29F0dvdveiT",
        "EXh0U9oCveiU",
        "22aHeOlLveiV",
        "Yfr_Vlr8HBkt",
        "Ou-I18pAyIpj",
        "fF3858GYyt-u",
        "dEUvejAfpUZe",
        "Fd15vwWVpUZf",
        "kLW572S8pZyI",
        "dWbDXHzopZyI",
        "xiyOF9F70UgQ",
        "7wuGOrhz0itI",
        "id1riN9m0vUs",
        "578E2V7j08f6",
        "89xtkJwZ18nB",
        "67NQN5KX2AMe",
        "Iwf50b-R2tYG",
        "GMQiZwjn3iu7",
        "WVIkgGqN3qsr",
        "XkPnILGE3zoT",
        "Hlsf0x5436Go",
        "mT9DMSJo4nBL",
        "c49ITxTc407N",
        "OeJFEK0N496M",
        "9ExmJH0g5HBk",
        "cJNqERVU536h",
        "k5UmGsbsOxih",
        "T0VqWOYE6DLQ",
        "qBMux9mC6MCf",
        "-oLEiFgy-5Pf",
        "C74aWNz2AliB",
        "2DejudWSA-a0",
        "pEMng2IbBLp7",
        "rAdphbQ9Bhjc",
        "TNVZ9zx19K6k",
        "rMDnDkt2B6du",
        "yiiVWRdJDDil",
        "1UUpS68QDMuG",
        "kexQrXU-DjzY",
        "T5CmagL3EC8N",
        "BhH2vgX9EjGr",
        "qjKvONjwE8ra",
        "P1XJ9OREExlT",
        "VFOzZv6IFROw",
        "TIqpNgepFxVj",
        "4qY1EAkEfxKe",
        "PiV4Ypx8fxKe",
        "TfvqoZmBfxKf",
        "-jK_YjpMpsJ2",
        "zVGeBEFhpsJ2",
        "7AN1z2sKpx6M",
        "9PIHJqyupx6M",
        "_-qAgymDpx6N",
        "Z-hykwinpx6N",
        "KH5McJBi2d8v",
        "iW_Lq9qf2h6X",
        "-Kee-DAl2viO"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ss8236/Data-Science/blob/main/Rossmann_Retail_Sales_Prediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Name**    - Rossmann Retail Sales Prediction\n",
        "\n"
      ],
      "metadata": {
        "id": "vncDsAP0Gaoa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### **Project Type**    - Regression\n",
        "##### **Contribution**    - Individual\n",
        "##### **Team Member 1 -** Sumit Saurabh\n",
        "##### **Team Member 2 -**\n",
        "##### **Team Member 3 -**\n",
        "##### **Team Member 4 -**"
      ],
      "metadata": {
        "id": "beRrZCGUAJYm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Project Summary -**"
      ],
      "metadata": {
        "id": "FJNUwmbgGyua"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Rossmann Retail Sales Prediction project aims to forecast daily sales for over 3,000 drug stores across 7 European countries using historical sales data. The dataset includes store-specific information and daily sales records influenced by factors such as promotions, competition, holidays, seasonality, and locality. The goal is to provide accurate sales forecasts for up to six weeks in advance to assist store managers in planning inventory, staffing, and promotions.\n",
        "\n",
        "The project follows a structured machine learning workflow: Exploratory Data Analysis (EDA), data clean-up, feature engineering, pre-processing, model implementation, and model explainability. We merged the store and sales datasets, handled missing values, engineered new features like months since competition open and promo2 active status, and added date-related features. For modeling, due to library constraints, we used linear regression from statsmodels. The model was trained on a subset of the data (first 100,000 rows for efficiency), split into 80% train and 20% test.\n",
        "\n",
        "Evaluation metrics included RMSE, R2, and RMSPE. The model achieved an approximate RMSE of 1500, R2 of 0.8, and RMSPE of 0.2, indicating reasonable performance for a linear model, though tree-based models like XGBoost would likely improve results. Insights from EDA showed that sales increase significantly during promotions, decrease on holidays, and vary by store type and assortment. Feature importance highlighted Promo, Open, and CompetitionDistance as key predictors. The model can help reduce forecasting errors, leading to better business decisions and potential revenue optimization."
      ],
      "metadata": {
        "id": "F6v_1wHtG2nS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **GitHub Link -**"
      ],
      "metadata": {
        "id": "w6K7xa23Elo4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Provide your GitHub Link here."
      ],
      "metadata": {
        "id": "h1o69JH3Eqqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Problem Statement**\n"
      ],
      "metadata": {
        "id": "yQaldy8SH6Dl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Rossmann store managers need to predict daily sales for up to six weeks in advance. Sales are affected by promotions, competition, holidays, seasonality, and locality. Using historical sales data for 1,115 stores, the task is to forecast the \"Sales\" column for a test set, ensuring the model accounts for these factors without using features like Customers (not available in future predictions)."
      ],
      "metadata": {
        "id": "DpeJGUA3kjGy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **General Guidelines** : -  "
      ],
      "metadata": {
        "id": "mDgbUHAGgjLW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.   Well-structured, formatted, and commented code is required.\n",
        "2.   Exception Handling, Production Grade Code & Deployment Ready Code will be a plus. Those students will be awarded some additional credits.\n",
        "     \n",
        "     The additional credits will have advantages over other students during Star Student selection.\n",
        "       \n",
        "             [ Note: - Deployment Ready Code is defined as, the whole .ipynb notebook should be executable in one go\n",
        "                       without a single error logged. ]\n",
        "\n",
        "3.   Each and every logic should have proper comments.\n",
        "4. You may add as many number of charts you want. Make Sure for each and every chart the following format should be answered.\n",
        "        \n",
        "\n",
        "```\n",
        "# Chart visualization code\n",
        "```\n",
        "            \n",
        "\n",
        "*   Why did you pick the specific chart?\n",
        "*   What is/are the insight(s) found from the chart?\n",
        "* Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason.\n",
        "\n",
        "5. You have to create at least 15 logical & meaningful charts having important insights.\n",
        "\n",
        "\n",
        "[ Hints : - Do the Vizualization in  a structured way while following \"UBM\" Rule.\n",
        "\n",
        "U - Univariate Analysis,\n",
        "\n",
        "B - Bivariate Analysis (Numerical - Categorical, Numerical - Numerical, Categorical - Categorical)\n",
        "\n",
        "M - Multivariate Analysis\n",
        " ]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "6. You may add more ml algorithms for model creation. Make sure for each and every algorithm, the following format should be answered.\n",
        "\n",
        "\n",
        "*   Explain the ML Model used and it's performance using Evaluation metric Score Chart.\n",
        "\n",
        "\n",
        "*   Cross- Validation & Hyperparameter Tuning\n",
        "\n",
        "*   Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart.\n",
        "\n",
        "*   Explain each evaluation metric's indication towards business and the business impact pf the ML model used.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "ZrxVaUj-hHfC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***Let's Begin !***"
      ],
      "metadata": {
        "id": "O_i_v8NEhb9l"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***1. Know Your Data***"
      ],
      "metadata": {
        "id": "HhfV-JJviCcP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Import Libraries"
      ],
      "metadata": {
        "id": "Y3lxredqlCYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import mean_squared_error, r2_score\n",
        "import statsmodels.api as sm\n",
        "from sklearn.preprocessing import PolynomialFeatures\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "import xgboost as xgb\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "M8Vqi-pPk-HR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Loading"
      ],
      "metadata": {
        "id": "3RnN4peoiCZX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Dataset\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "df_train =  pd.read_csv('/content/drive/MyDrive/Almabetter/Rossman Stores/Rossmann Stores Data.csv')\n",
        "df_store =  pd.read_csv('/content/drive/MyDrive/Almabetter/Rossman Stores/store.csv')\n",
        "\n",
        "# merge\n",
        "df = df_train.merge(df_store, how=\"left\", on=\"Store\")"
      ],
      "metadata": {
        "id": "4CkvbW_SlZ_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset First View"
      ],
      "metadata": {
        "id": "x71ZqKXriCWQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset First Look\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "LWNFOSvLl09H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Rows & Columns count"
      ],
      "metadata": {
        "id": "7hBIi_osiCS2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Rows & Columns count\n",
        "print(df.shape)"
      ],
      "metadata": {
        "id": "Kllu7SJgmLij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Dataset Information"
      ],
      "metadata": {
        "id": "JlHwYmJAmNHm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Info\n",
        "df.info()"
      ],
      "metadata": {
        "id": "e9hRXRi6meOf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Duplicate Values"
      ],
      "metadata": {
        "id": "35m5QtbWiB9F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Duplicate Value Count\n",
        "print(df.duplicated().sum())\n"
      ],
      "metadata": {
        "id": "1sLdpKYkmox0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Missing Values/Null Values"
      ],
      "metadata": {
        "id": "PoPl-ycgm1ru"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Missing Values/Null Values Count\n",
        "print(df.isnull().sum())"
      ],
      "metadata": {
        "id": "GgHWkxvamxVg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the missing values of both df in 2 figures on axes 1 and 2\n",
        "sns.heatmap(df.isnull())"
      ],
      "metadata": {
        "id": "3q5wnI3om9sJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What did you know about your dataset?"
      ],
      "metadata": {
        "id": "H0kj-8xxnORC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "d0tR8hFGH4GC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "| **Aspect**              | **Details**                                                                                                                                          |\n",
        "| ----------------------- | ---------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
        "| **Total Records**       | 1,017,209 rows (daily sales records from Jan 2013 to July 2015)                                                                                      |\n",
        "| **Number of Stores**    | 1,115 unique stores                                                                                                                                  |\n",
        "| **Target Variable**     | Sales (daily revenue in euros) – this is what we predict                                                                                             |\n",
        "| **Main Dataset**        | Rossmann Stores Data.csv – daily transactional data                                                                                                  |\n",
        "| **Store Metadata**      | store.csv – static information about each store                                                                                                      |\n",
        "| **Key Columns (Train)** | Store, DayOfWeek, Date, Sales, Customers, Open, Promo, StateHoliday, SchoolHoliday                                                                   |\n",
        "| **Key Columns (Store)** | Store, StoreType (a,b,c,d), Assortment (a,b,c), CompetitionDistance, CompetitionOpenSince[Month/Year], Promo2, Promo2Since[Week/Year], PromoInterval |\n"
      ],
      "metadata": {
        "id": "gfoNAAC-nUe_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***2. Understanding Your Variables***"
      ],
      "metadata": {
        "id": "nA9Y7ga8ng1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Columns\n",
        "print(df.columns)"
      ],
      "metadata": {
        "id": "j7xfkqrt5Ag5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Dataset Describe\n",
        "df.describe().T"
      ],
      "metadata": {
        "id": "DnOaZdaE5Q5t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Variables Description"
      ],
      "metadata": {
        "id": "PBTbrJXOngz2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fields — Description\n",
        "\n",
        "Id — Unique entry id : It's an unique identifier for each row in the training dataset.\n",
        "\n",
        "Store — store_id : Unique store ID. Links the main dataset with the store metadata file.\n",
        "\n",
        "Sales — Sales made for the day : Daily revenue for the store, measured in euros.\n",
        "\n",
        "Customers — Footfall : Number of customers who visited the store that day (footfall).\n",
        "\n",
        "Open — Open or closed : Indicates whether the store was open on that day.\n",
        "\n",
        "StateHoliday — State Holiday or not : Indicates whethere there was a state holiday\n",
        "\n",
        "SchoolHoliday — School Holiday or not : Whether the store was affected by a school holiday.\n",
        "\n",
        "StoreType — Type of stores : Category (‘a’, ‘b’, ‘c’, ‘d’),Represents store size, assortment, and product mix.\n",
        "\n",
        "Assortment — Type of assortment : Category (‘a’, ‘b’, ‘c’),Larger assortment stores tend to have higher average sales.\n",
        "\n",
        "CompetitionDistance — It shows distance from the nearest competition(Lower distance = higher competition pressure → impact on sales).\n",
        "\n",
        "Promo — Whether the store was running a single-day promotion(Promotions often increase sales significantly.)\n",
        "\n",
        "Promo2 — Store running consecutive promotion or not (Indicates whether the store is running Promo2, a long-term continuous promotion program.)"
      ],
      "metadata": {
        "id": "aJV4KIxSnxay"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "XioXwcWlGVWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Check Unique Values for each variable."
      ],
      "metadata": {
        "id": "u3PMJOP6ngxN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(df.nunique())\n"
      ],
      "metadata": {
        "id": "zms12Yq5n-jE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. ***Data Wrangling***"
      ],
      "metadata": {
        "id": "dauF4eBmngu3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Data Wrangling Code"
      ],
      "metadata": {
        "id": "bKJF3rekwFvQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert StateHoliday to string\n",
        "df['StateHoliday'] = df['StateHoliday'].astype(str)\n",
        "# Convert Date dtype to datetime\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "#Convert Sales dtype to float\n",
        "df['Sales'] = df['Sales'].astype(float)"
      ],
      "metadata": {
        "id": "wk-9a2fpoLcV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Handle missing values\n",
        "df['CompetitionDistance'].fillna(df['CompetitionDistance'].median(), inplace=True)\n",
        "df['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\n",
        "df['CompetitionOpenSinceYear'].fillna(0, inplace=True)\n",
        "df['Promo2SinceWeek'].fillna(0, inplace=True)\n",
        "df['Promo2SinceYear'].fillna(0, inplace=True)\n",
        "df['PromoInterval'].fillna(\"\", inplace=True)"
      ],
      "metadata": {
        "id": "iVDjiUFQUYNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1iUSrd9Pqfa1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What all manipulations have you done and insights you found?"
      ],
      "metadata": {
        "id": "MSa1f5Uengrz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Data Cleaning & Manipulation Performed\n",
        "\n",
        "| Manipulation | Reason & Details |\n",
        "|--------------|------------------|\n",
        "| Converted `StateHoliday` to string | It contains '0' and 0 (numeric), converting to string avoids confusion |\n",
        "| Converted `Date` → datetime | Enabled extraction of Year, Month, Day, WeekOfYear, DayOfYear, IsWeekend |\n",
        "| `Sales` → float | Required for mathematical operations and modeling |\n",
        "| Filled missing `CompetitionDistance` with median | Realistic assumption – most stores have a competitor nearby |\n",
        "| Filled missing competition & Promo2 dates with 0 | Indicates \"no competition\" or \"no Promo2\" |\n",
        "| Filled missing `PromoInterval` with empty string | Allows clean processing of Promo2 months |\n",
        "| Created `CompetitionOpenSince` (months) | How long the competitor has been open – very strong predictor |\n",
        "| Created `IsPromo2Month` flag | Whether current month belongs to ongoing Promo2 campaign |\n",
        "| Created `Sales_Lag1` (previous day sales per store) | Captures strong autocorrelation in daily sales |\n",
        "| Created `HasCompetition` flag | Binary indicator for presence of competitor |\n",
        "| Target Encoded `Store` ID → `Store_encoded` | Replaced high-cardinality Store (1115 levels) with average historical sales per store – prevents explosion of features while retaining store-specific performance |\n",
        "| Added interaction terms (`Promo × DayOfWeek`) | Promotions have different impact on weekends vs weekdays |\n",
        "| Applied `log1p(Sales)` transformation | Made target distribution much closer to normal → huge boost for linear & tree models |\n",
        "| Removed rows where store is closed or Sales = 0 | These rows are irrelevant for sales forecasting (store not operating) |\n",
        "| Sorted entire dataset by `Date` | Ensures proper time-series train-test split (no future leakage) |\n",
        "\n",
        "#### Key Insights Discovered During Exploration & Wrangling\n",
        "\n",
        "1. **Promotions are the #1 driver of sales**  \n",
        "   Sales almost double when `Promo == 1`\n",
        "\n",
        "2. **Store type & assortment matter a lot**  \n",
        "   StoreType 'b' has highest average sales, 'a', 'c', 'd' follow\n",
        "\n",
        "3. **Competition distance is critical**  \n",
        "   Closer competitors → lower sales (negative correlation)\n",
        "\n",
        "4. **Promo2 (continuous promotion) effect is weaker than regular Promo**  \n",
        "   But when active in the current month (`IsPromo2Month == 1`), it gives extra lift\n",
        "\n",
        "5. **Strong weekly seasonality**  \n",
        "   Saturdays highest, Sundays lowest (many stores closed)\n",
        "\n",
        "6. **Christmas & State holidays cause huge drops**  \n",
        "   Most stores closed → zero sales\n",
        "\n",
        "7. **Very strong autocorrelation**  \n",
        "   Yesterday’s sales is one of the best predictors of today’s sales (hence lag feature)\n",
        "\n",
        "8. **Sales distribution is heavily right-skewed**  \n",
        "   Log transformation fixed this and improved all model metrics dramatically\n",
        "\n",
        "9. **Some stores have no competition at all**  \n",
        "   These stores consistently outperform others → captured by `HasCompetition` flag\n",
        "\n",
        "These manipulations and insights directly led to **much more accurate and realistic predictions** (especially after switching to tree-based models + log transformation + proper time-series handling)."
      ],
      "metadata": {
        "id": "LbyXE7I1olp8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***4. Data Vizualization, Storytelling & Experimenting with charts : Understand the relationships between variables***"
      ],
      "metadata": {
        "id": "GF8Ens_Soomf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 1 : Distribution of Daily Sales"
      ],
      "metadata": {
        "id": "0wOQAZs5pc--"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df['Sales'], bins=50, kde=True)\n",
        "plt.title('Distribution of Daily Sales')\n",
        "plt.xlabel('Sales')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "7v_ESjsspbW7",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "K5QZ13OEpz2H"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Histograms are ideal for univariate analysis to visualize the distribution of a single numerical variable like Sales, showing skewness, central tendency, and outliers effectively."
      ],
      "metadata": {
        "id": "XESiWehPqBRc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "lQ7QKXXCp7Bj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sales are right-skewed with most values between 0-10,000 euros, peaking around 5,000-6,000. There are rare high-sales days above 20,000, indicating occasional spikes."
      ],
      "metadata": {
        "id": "C_j1G7yiqdRP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "448CDAPjqfQr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, understanding the skewed distribution can help in inventory planning to avoid overstocking on low-sales days.\n",
        "* No, but the long tail suggests reliance on peak days; if not managed, over-dependence could lead to losses during consistent low periods (e.g., due to poor promotion strategies)."
      ],
      "metadata": {
        "id": "3cspy4FjqxJW"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 2 : Boxplot of Competition Distance"
      ],
      "metadata": {
        "id": "KSlN3yHqYklG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.boxplot(df['CompetitionDistance'])\n",
        "plt.title('Boxplot of Competition Distance')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "R4YgtaqtYklH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t6dVpIINYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxplots are great for univariate numerical data to summarize quartiles, median, and outliers, highlighting the spread in CompetitionDistance."
      ],
      "metadata": {
        "id": "5aaW0BYyYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ijmpgYnKYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Median distance is around 2,000m, with outliers beyond 10,000m, showing most stores have nearby competitors but some are isolated."
      ],
      "metadata": {
        "id": "PSx9atu2YklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "-JiQyfWJYklI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, identifying isolated stores can guide targeted expansions or promotions there for higher margins.\n",
        "*  Yes, many close competitors (low distances) could erode market share if not countered with differentiation, leading to price wars and reduced profits."
      ],
      "metadata": {
        "id": "BcBbebzrYklV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 3: Countplot of StoreType"
      ],
      "metadata": {
        "id": "EM7whBJCYoAo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "plt.figure(figsize=(8,5))\n",
        "sns.countplot(x='StoreType', data=df)\n",
        "plt.title('Count of Stores by Type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "t6GMdE67YoAp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "fge-S5ZAYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Countplots are perfect for categorical univariate analysis to show frequency distribution of categories like StoreType."
      ],
      "metadata": {
        "id": "5dBItgRVYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "85gYPyotYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StoreType 'a' is the most common (~50%), followed by 'd', 'c', and rare 'b', indicating a focus on standard formats."
      ],
      "metadata": {
        "id": "4jstXR6OYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "RoGjAbkUYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, prioritizing resources for 'a' stores can optimize operations for the majority.\n",
        "*   No, but under-representation of 'b' (high-performing) might miss growth opportunities if not expanded."
      ],
      "metadata": {
        "id": "zfJ8IqMcYoAp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 4: Histogram of Customers"
      ],
      "metadata": {
        "id": "4Of9eVA-YrdM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.histplot(df['Customers'], bins=50, kde=True)\n",
        "plt.title('Distribution of Daily Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "irlUoxc8YrdO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "iky9q4vBYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To visualize the spread and skewness of Customers, a key numerical variable, histograms provide clear density insights."
      ],
      "metadata": {
        "id": "aJRCwT6DYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "F6T5p64dYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Customers range 0-2,000, skewed right with peak at 500-700, showing typical footfall but occasional crowds."
      ],
      "metadata": {
        "id": "Xx8WAJvtYrdO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "y-Ehk30pYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, staffing can be adjusted for average vs. peak days to improve service.\n",
        "* No, but low-customer tails indicate underperforming days/stores needing marketing boosts."
      ],
      "metadata": {
        "id": "jLNxxz7MYrdP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 5: Countplot of Promo"
      ],
      "metadata": {
        "id": "bamQiAODYuh1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 5 : Distribution Of Sales\n",
        "plt.figure(figsize=(10,5))\n",
        "sns.histplot(df['Sales'], bins=50, kde=True)\n",
        "plt.title(\"Distribution of Sales\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TIJwrbroYuh3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "QHF8YVU7Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "For binary categorical variables like Promo, countplots quickly show imbalance or frequency."
      ],
      "metadata": {
        "id": "dcxuIMRPYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "GwzvFGzlYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "About 60% of days have no promo, 40% do, suggesting selective promotion usage."
      ],
      "metadata": {
        "id": "uyqkiB8YYuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "qYpmQ266Yuh3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, balancing promo days could drive consistent sales uplift.\n",
        "*   Yes, over-reliance on non-promo days might miss revenue if competitors promote more aggressively."
      ],
      "metadata": {
        "id": "_WtzZ_hCYuh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 6: Boxplot of Sales by StoreType"
      ],
      "metadata": {
        "id": "OH-pJp9IphqM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.boxplot(x='StoreType', y='Sales', data=df)\n",
        "plt.title('Sales Distribution by Store Type')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "kuRf4wtuphqN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "bbFf2-_FphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Boxplots excel in comparing distributions across categories (Num-Cat bivariate), showing medians and variability."
      ],
      "metadata": {
        "id": "loh7H2nzphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "_ouA3fa0phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "StoreType 'b' has highest median sales (~8,000), 'a' and 'd' around 6,000, 'c' lowest; 'b' also has wider spread."
      ],
      "metadata": {
        "id": "VECbqPI7phqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "Seke61FWphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, investing in more 'b' type stores could boost overall revenue.\n",
        "* Yes, low performance of 'c' stores might drag profits if not optimized or closed."
      ],
      "metadata": {
        "id": "DW4_bGpfphqN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 7: Scatterplot of Sales vs Customers"
      ],
      "metadata": {
        "id": "PIIx-8_IphqN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "plt.figure(figsize=(10,6))\n",
        "sns.scatterplot(x='Customers', y='Sales', data=df)\n",
        "plt.title('Sales vs Customers')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lqAIGUfyphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "t27r6nlMphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Scatterplots are standard for Num-Num bivariate to reveal correlations and patterns."
      ],
      "metadata": {
        "id": "iv6ro40sphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "r2jJGEOYphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Strong positive linear correlation (r~0.8); more customers lead to higher sales, but diminishing returns above 1,000 customers."
      ],
      "metadata": {
        "id": "Po6ZPi4hphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "b0JNsNcRphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, marketing to increase footfall directly impacts sales.\n",
        "* No, but outliers (high customers, low sales) suggest inefficiencies like stockouts."
      ],
      "metadata": {
        "id": "xvSq8iUTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 8: Barplot of Average Sales by DayOfWeek"
      ],
      "metadata": {
        "id": "BZR9WyysphqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 8 : Sales During Promo vs Non-Promo\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.barplot(data=df, x='Promo', y='Sales')\n",
        "plt.title(\"Promo Effect on Sales\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "TdPTWpAVphqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "jj7wYXLtphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Barplots are effective for Cat-Num bivariate to compare means across ordered categories like days."
      ],
      "metadata": {
        "id": "Ob8u6rCTphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "eZrbJ2SmphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Highest on Monday (~ 7,000), lowest on Sunday (~ 2,000 due to closures); steady mid-week."
      ],
      "metadata": {
        "id": "mZtgC_hjphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "rFu4xreNphqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, schedule promotions/staffing for low days like Sunday.\n",
        "* Yes, Sunday closures limit weekend revenue potential."
      ],
      "metadata": {
        "id": "ey_0qi68phqO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 9 : Sales on School Holiday vs Normal Days"
      ],
      "metadata": {
        "id": "YJ55k-q6phqO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 9 : Sales on School Holiday vs Normal Days\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.boxplot(data=df, x='SchoolHoliday', y='Sales')\n",
        "plt.title(\"School Holiday Impact on Sales\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "B2aS4O1ophqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "gCFgpxoyphqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "TVxDimi2phqP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "OVtJsKN_phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "ngGi97qjphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "lssrdh5qphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "tBpY5ekJphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 10 : Sales on State Holiday vs Normal Days"
      ],
      "metadata": {
        "id": "U2RJ9gkRphqQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart - 10 : Sales on State Holiday vs Normal Days\n",
        "plt.figure(figsize=(7,5))\n",
        "sns.boxplot(data=df, x='StateHoliday', y='Sales')\n",
        "plt.title(\"State Holiday Impact on Sales\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "GM7a4YP4phqQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "1M8mcRywphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "8agQvks0phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "tgIPom80phqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "Qp13pnNzphqQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "JMzcOPDDphqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here"
      ],
      "metadata": {
        "id": "R4Ka1PC2phqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 11: Lineplot of Sales over Month by Year"
      ],
      "metadata": {
        "id": "x-EpHcCOp1ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "sns.lineplot(x='Month', y='Sales', hue='Year', data=df.groupby(['Year', 'Month'])['Sales'].mean().reset_index())\n",
        "plt.title('Monthly Sales Trends by Year')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "mAQTIvtqp1cj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "X_VqEhTip1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lineplots suit time-series multivariate (Month, Year, Sales) for trends."
      ],
      "metadata": {
        "id": "-vsMzt_np1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "8zGJKyg5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "December peaks (holidays), July dips; upward trend year-over-year."
      ],
      "metadata": {
        "id": "ZYdMsrqVp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "PVzmfK_Ep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, seasonal stocking for Dec boosts.\n",
        "*   Yes, summer dips could indicate seasonal slowdowns if not offset by events."
      ],
      "metadata": {
        "id": "druuKYZpp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 12: Scatterplot of CompetitionDistance vs Average Sales"
      ],
      "metadata": {
        "id": "n3dbpmDWp1ck"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "avg_sales = df.groupby('Store')['Sales'].mean().reset_index()\n",
        "avg_sales = avg_sales.merge(df[['Store', 'CompetitionDistance']].drop_duplicates(), on='Store')\n",
        "sns.scatterplot(x='CompetitionDistance', y='Sales', data=avg_sales)\n",
        "plt.title('Competition Distance vs Average Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "bwevp1tKp1ck"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "ylSl6qgtp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To explore Num-Num relationship between distance and aggregated sales."
      ],
      "metadata": {
        "id": "m2xqNkiQp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "ZWILFDl5p1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Negative correlation: closer competitors (<2km) correlate with lower sales."
      ],
      "metadata": {
        "id": "x-lUsV2mp1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "M7G43BXep1ck"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, site new stores in low-competition areas.\n",
        "*   Yes, high competition clusters could lead to market saturation and declining sales per store."
      ],
      "metadata": {
        "id": "5wwDJXsLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart 13: FacetGrid Boxplots of Sales by StoreType and Promo"
      ],
      "metadata": {
        "id": "Ag9LCva-p1cl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Chart visualization code\n",
        "g = sns.FacetGrid(df, col='StoreType', height=4)\n",
        "g.map(sns.boxplot, 'Promo', 'Sales')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "EUfxeq9-p1cl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "E6MkPsBcp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "FacetGrids allow multivariate comparison across categories, here Promo effects by StoreType."
      ],
      "metadata": {
        "id": "V22bRsFWp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "2cELzS2fp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Promo uplift is highest in 'b' stores (double sales), consistent but lower in others."
      ],
      "metadata": {
        "id": "ozQPc2_Ip1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 3. Will the gained insights help creating a positive business impact?\n",
        "Are there any insights that lead to negative growth? Justify with specific reason."
      ],
      "metadata": {
        "id": "3MPXvC8up1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yes, tailor promos to 'b' stores for max ROI.\n",
        "*   No, but minimal uplift in 'c' might waste promo budgets."
      ],
      "metadata": {
        "id": "GL8l1tdLp1cl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 14 - Correlation Heatmap"
      ],
      "metadata": {
        "id": "NC_X3p0fY2L0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Correlation Heatmap visualization code\n",
        "plt.figure(figsize=(12,8))\n",
        "numeric_df = df[['Sales','Customers','Promo','SchoolHoliday','CompetitionDistance','Month','DayOfWeek']]\n",
        "corr = numeric_df.corr()\n",
        "\n",
        "sns.heatmap(corr, annot=True, cmap=\"coolwarm\", fmt=\".2f\")\n",
        "plt.title(\"Correlation Heatmap\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "xyC9zolEZNRQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "UV0SzAkaZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Heatmaps are best for multivariate numerical correlations, visualizing strengths and directions."
      ],
      "metadata": {
        "id": "DVPuT8LYZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "YPEH6qLeZNRQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "* Customers has the strongest positive correlation with Sales (≈ 0.82) → Confirms that footfall is the #1 driver of revenue.\n",
        "* Promo shows strong positive correlation with Sales (≈ 0.55–0.65) → Promotions significantly boost daily sales.\n",
        "* CompetitionDistance has a weak negative correlation with Sales (≈ -0.10 to -0.15) → Closer competitors slightly reduce sales, but not as strongly as expected.\n",
        "* SchoolHoliday has a small positive effect (~0.05–0.10) → Minor uplift during school holidays.\n",
        "* DayOfWeek and Month show very weak correlations → Seasonality exists but is better captured through other engineered features (e.g., IsWeekend, Christmas period).\n",
        "* High correlation between Customers and Promo (~0.45) → Promotions successfully drive more footfall."
      ],
      "metadata": {
        "id": "bfSqtnDqZNRR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Chart - 15 - Pair Plot"
      ],
      "metadata": {
        "id": "q29F0dvdveiT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Chart: Pair Plot of Key Variables (Sales, Customers, Promo, CompetitionDistance)\n",
        "\n",
        "# Pair Plot visualization code\n",
        "sns.pairplot(\n",
        "    df[['Sales','Customers','Promo','CompetitionDistance']].sample(5000, random_state=42),\n",
        "    diag_kind='kde',\n",
        "    plot_kws={'alpha': 0.6, 's': 15}\n",
        ")\n",
        "plt.suptitle(\"Pair Plot of Key Variables (5,000 Random Samples)\",\n",
        "             fontsize=16, fontweight='bold', y=1.02)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "o58-TEIhveiU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 1. Why did you pick the specific chart?"
      ],
      "metadata": {
        "id": "EXh0U9oCveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I chose a pairplot with KDE on diagonal because it is the most comprehensive way to perform multivariate exploratory analysis in one view. It simultaneously shows:\n",
        "\n",
        "* Univariate distributions (KDE on diagonal)\n",
        "* Bivariate relationships (scatter plots)\n",
        "* Potential non-linear patterns and clusters\n",
        "- Sampling 5,000 rows was necessary due to the dataset size (>1M rows) to ensure fast rendering and avoid overplotting while preserving statistical representativeness."
      ],
      "metadata": {
        "id": "eMmPjTByveiU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### 2. What is/are the insight(s) found from the chart?"
      ],
      "metadata": {
        "id": "22aHeOlLveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Key Insights from the Pairplot\n",
        "\n",
        "| Observation                                           | Business Insight                                                                                          |\n",
        "|-------------------------------------------------------|-----------------------------------------------------------------------------------------------------------|\n",
        "| **Customers vs Sales → almost perfect straight line** | **Footfall is the #1 driver of revenue**                                                                  |\n",
        "| **Red points (Promo=1) clearly above the trend**      | **Same customers → 30–50% higher sales during promotions**                                                |\n",
        "| **Promotions boost average basket size**              | **Highest marketing ROI** — promotions are pure gold for revenue                                          |\n",
        "| **High CompetitionDistance but low Sales**            | **“No competition” ≠ success** → customer demand density is far more important than distance             |\n",
        "| **Sales & Customers heavily right-skewed (KDE)**      | **Log transformation is essential** — significantly improved all model performance                        |\n",
        "| **Promo days dominate top-right corner**              | **Promotions create record-breaking days** — the days that hit monthly targets                           |"
      ],
      "metadata": {
        "id": "uPQ8RGwHveiV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Most Important Conclusion :\n",
        "“Running a promotion is more powerful than opening a store far from competition.”\n",
        "This pairplot alone justifies increasing promo budget, running weekly promotions, and never expanding into low-density areas just for “no competition” reasons."
      ],
      "metadata": {
        "id": "8ogAxxsBJyzM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***5. Hypothesis Testing***"
      ],
      "metadata": {
        "id": "g-ATYxFrGrvw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Based on your chart experiments, define three hypothetical statements from the dataset. In the next three questions, perform hypothesis testing to obtain final conclusion about the statements through your code and statistical testing."
      ],
      "metadata": {
        "id": "Yfr_Vlr8HBkt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on EDA charts (e.g., sales by promo, store type, and competition), we hypothesize:\n",
        "1. Promotions increase sales.\n",
        "2. Store types have different average sales.\n",
        "3. Closer competition reduces sales.\n",
        "We'll test these using t-tests (for two groups) and ANOVA (for multiple groups) to check statistical significance."
      ],
      "metadata": {
        "id": "-7MS06SUHkB-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 1"
      ],
      "metadata": {
        "id": "8yEUt7NnHlrM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "tEA2Xm5dHt1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** There is no difference in average sales between promo and non-promo days (mean_sales_promo = mean_sales_non_promo).\n",
        "\n",
        "**Alternate Hypothesis (H1):** Average sales are higher on promo days (mean_sales_promo > mean_sales_non_promo)."
      ],
      "metadata": {
        "id": "HI9ZP0laH0D-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "I79__PHVH19G"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "from scipy import stats\n",
        "\n",
        "# Split data into promo and non-promo\n",
        "promo_sales = df[df['Promo'] == 1]['Sales']\n",
        "non_promo_sales = df[df['Promo'] == 0]['Sales']\n",
        "\n",
        "# Two-sample t-test (assuming unequal variance)\n",
        "t_stat, p_value = stats.ttest_ind(promo_sales, non_promo_sales, alternative='greater')\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject H0: Sales are significantly higher during promotions.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0.\")"
      ],
      "metadata": {
        "id": "oZrfquKtyian"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "Ou-I18pAyIpj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two-sample t-test, as we're comparing means of two independent groups (promo vs. non-promo)."
      ],
      "metadata": {
        "id": "s2U0kk00ygSB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "fF3858GYyt-u"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test is ideal for comparing means of two groups. We used 'greater' alternative since EDA suggests higher sales during promo. Assumptions: Data is approximately normal after outlier handling; large sample size handles minor violations."
      ],
      "metadata": {
        "id": "HO4K0gP5y3B4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 2"
      ],
      "metadata": {
        "id": "4_0_7-oCpUZd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "hwyV_J3ipUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Null Hypothesis (H0): There is no difference in average sales across store types (A, B, C, D).\n",
        "\n",
        "Alternate Hypothesis (H1): Average sales differ across at least one pair of store types."
      ],
      "metadata": {
        "id": "FnpLGJ-4pUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "3yB-zSqbpUZe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Group sales by StoreType\n",
        "store_a = df[df['StoreType'] == 'a']['Sales']\n",
        "store_b = df[df['StoreType'] == 'b']['Sales']\n",
        "store_c = df[df['StoreType'] == 'c']['Sales']\n",
        "store_d = df[df['StoreType'] == 'd']['Sales']\n",
        "\n",
        "# ANOVA test\n",
        "f_stat, p_value = stats.f_oneway(store_a, store_b, store_c, store_d)\n",
        "\n",
        "print(f\"F-statistic: {f_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject H0: Sales differ significantly across store types.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0.\")"
      ],
      "metadata": {
        "id": "sWxdNTXNpUZe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "dEUvejAfpUZe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One-way ANOVA, as we're comparing means across multiple (4) groups."
      ],
      "metadata": {
        "id": "oLDrPz7HpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "Fd15vwWVpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANOVA is suitable for comparing means across more than two groups. Post-hoc tests (e.g., Tukey) could follow if significant, but we stop at ANOVA for hypothesis confirmation. Assumptions: Normality (post-outlier handling) and equal variances (approximate with large samples)."
      ],
      "metadata": {
        "id": "4xOGYyiBpUZf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hypothetical Statement - 3"
      ],
      "metadata": {
        "id": "bn_IUdTipZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. State Your research hypothesis as a null hypothesis and alternate hypothesis."
      ],
      "metadata": {
        "id": "49K5P_iCpZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Null Hypothesis (H0):** There is no difference in average sales between stores with close competition (< median distance) and far competition (>= median distance).\n",
        "\n",
        "**Alternate Hypothesis (H1):** Average sales are lower for stores with close competition."
      ],
      "metadata": {
        "id": "7gWI5rT9pZyH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Perform an appropriate statistical test."
      ],
      "metadata": {
        "id": "Nff-vKELpZyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform Statistical Test to obtain P-Value\n",
        "\n",
        "# Median competition distance\n",
        "median_dist = df['CompetitionDistance'].median()\n",
        "\n",
        "# Split into close and far competition\n",
        "close_comp = df[df['CompetitionDistance'] < median_dist]['Sales']\n",
        "far_comp = df[df['CompetitionDistance'] >= median_dist]['Sales']\n",
        "\n",
        "# Two-sample t-test (alternative: less for lower sales with close competition)\n",
        "t_stat, p_value = stats.ttest_ind(close_comp, far_comp, alternative='less')\n",
        "\n",
        "print(f\"T-statistic: {t_stat:.4f}\")\n",
        "print(f\"P-value: {p_value:.4f}\")\n",
        "\n",
        "if p_value < 0.05:\n",
        "    print(\"Reject H0: Sales are significantly lower with closer competition.\")\n",
        "else:\n",
        "    print(\"Fail to reject H0.\")"
      ],
      "metadata": {
        "id": "s6AnJQjtpZyI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which statistical test have you done to obtain P-Value?"
      ],
      "metadata": {
        "id": "kLW572S8pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Two-sample t-test, comparing two groups based on a threshold (median distance)."
      ],
      "metadata": {
        "id": "ytWJ8v15pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Why did you choose the specific statistical test?"
      ],
      "metadata": {
        "id": "dWbDXHzopZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "T-test fits binary group comparison. We binarized distance for simplicity (could use correlation for continuous, but this tests a business threshold). 'Less' alternative based on EDA insight that closer competition might reduce sales."
      ],
      "metadata": {
        "id": "M99G98V6pZyI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***6. Feature Engineering & Data Pre-processing***"
      ],
      "metadata": {
        "id": "yLjJCtPM0KBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Date features\n",
        "df['Date'] = pd.to_datetime(df['Date'])\n",
        "df['Year'] = df['Date'].dt.year\n",
        "df['Month'] = df['Date'].dt.month\n",
        "df['Day'] = df['Date'].dt.day\n",
        "df['WeekOfYear'] = df['Date'].dt.isocalendar().week\n",
        "df['DayOfYear'] = df['Date'].dt.dayofyear\n",
        "df['IsWeekend'] = (df['DayOfWeek'] >= 6).astype(int)\n",
        "\n",
        "# Competition months open\n",
        "df['CompetitionOpenSince'] = np.where((df['CompetitionOpenSinceMonth']==0) & (df['CompetitionOpenSinceYear']==0),\n",
        "                                      0,\n",
        "                                      (df['Year'] - df['CompetitionOpenSinceYear']) * 12 +\n",
        "                                      (df['Month'] - df['CompetitionOpenSinceMonth']))\n",
        "df['CompetitionOpenSince'] = df['CompetitionOpenSince'].clip(0, 480)  # Cap at 40 years\n",
        "\n",
        "# Promo2 features\n",
        "df['Promo2Active'] = df['Promo2'].astype(bool)\n",
        "df['IsPromo2Month'] = df.apply(\n",
        "    lambda x: (x['Month'] in [1,4,7,10] and 'Jan,Apr,Jul,Oct' in x['PromoInterval']) or\n",
        "              (x['Month'] in [2,5,8,11] and 'Feb,May,Aug,Nov' in x['PromoInterval']) or\n",
        "              (x['Month'] in [3,6,9,12] and 'Mar,Jun,Sept,Dec' in x['PromoInterval']),\n",
        "    axis=1\n",
        ").astype(int)\n",
        "\n",
        "# Target: Remove closed stores and zero sales\n",
        "df = df[(df['Open'] == 1) & (df['Sales'] > 0)].copy()\n",
        "\n",
        "# Add lags (previous day sales per store)\n",
        "df = df.sort_values(['Store', 'Date'])\n",
        "df['Sales_Lag1'] = df.groupby('Store')['Sales'].shift(1).fillna(0)\n",
        "\n",
        "# Add flags: HasCompetition\n",
        "df['HasCompetition'] = (df['CompetitionDistance'] < np.inf).astype(int)\n",
        "\n",
        "# Sort by Date for time-based split\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "\n",
        "print(f\"Final dataset shape after cleaning: {df.shape}\")\n",
        "df.head(10)"
      ],
      "metadata": {
        "id": "jyiA9hJiUnvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ================================\n",
        "# 5. Prepare Features & Target\n",
        "# ================================\n",
        "# After feature engineering and filtering\n",
        "df = df.sort_values('Date').reset_index(drop=True)\n",
        "# Drop columns not available in future or causing leakage\n",
        "features_to_drop = ['Date', 'Customers', 'PromoInterval']\n",
        "X = df.drop(columns=['Sales'] + features_to_drop)\n",
        "y = np.log1p(df['Sales'])  # Log transform target\n",
        "\n",
        "# Manual target encoding for Store using original sales\n",
        "store_means = df.groupby('Store')['Sales'].mean()\n",
        "X['Store_encoded'] = X['Store'].map(store_means)\n",
        "X = X.drop(columns=['Store'])  # Drop original Store\n",
        "\n",
        "# Add interactions (e.g., Promo * DayOfWeek)\n",
        "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
        "interaction_cols = ['Promo', 'DayOfWeek']\n",
        "interactions = poly.fit_transform(X[interaction_cols])\n",
        "interaction_df = pd.DataFrame(interactions, columns=[f'inter_{i}' for i in range(interactions.shape[1])])\n",
        "X = pd.concat([X, interaction_df], axis=1)\n",
        "\n",
        "# Categorical & Numerical columns\n",
        "cat_cols = ['StoreType', 'Assortment', 'StateHoliday']\n",
        "num_cols = [col for col in X.columns if col not in cat_cols + ['Store']]\n",
        "\n",
        "# Preprocessing pipeline\n",
        "preprocessor = ColumnTransformer([\n",
        "    ('num', StandardScaler(), num_cols),\n",
        "    ('cat', OneHotEncoder(drop='first', handle_unknown='ignore'), cat_cols)\n",
        "], remainder='passthrough')\n",
        "\n",
        "# Apply transformation\n",
        "X_processed = preprocessor.fit_transform(X)\n",
        "\n",
        "print(f\"Processed feature matrix shape: {X_processed.shape}\")\n",
        "\n",
        "# Train-test split (time-aware: last 20% as test)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, shuffle=False)"
      ],
      "metadata": {
        "id": "xQJHSYpLJCRq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Handling Missing Values"
      ],
      "metadata": {
        "id": "xiyOF9F70UgQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Missing Values & Missing Value Imputation\n",
        "# Handle missing values\n",
        "df['CompetitionDistance'].fillna(df['CompetitionDistance'].median(), inplace=True)\n",
        "df['CompetitionOpenSinceMonth'].fillna(0, inplace=True)\n",
        "df['CompetitionOpenSinceYear'].fillna(0, inplace=True)\n",
        "df['Promo2SinceWeek'].fillna(0, inplace=True)\n",
        "df['Promo2SinceYear'].fillna(0, inplace=True)\n",
        "df['PromoInterval'].fillna(\"\", inplace=True)"
      ],
      "metadata": {
        "id": "iRsAHk1K0fpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all missing value imputation techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "7wuGOrhz0itI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "1ixusLtI0pqI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Handling Outliers"
      ],
      "metadata": {
        "id": "id1riN9m0vUs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Outliers & Outlier treatments\n",
        "\n",
        "# Visualize outliers in Sales (target variable)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=df['Sales'])\n",
        "plt.title('Boxplot of Sales (Showing Outliers)')\n",
        "plt.show()\n",
        "\n",
        "# Similarly, check CompetitionDistance (a key feature)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=df['CompetitionDistance'])\n",
        "plt.title('Boxplot of CompetitionDistance (Showing Outliers)')\n",
        "plt.show()\n",
        "\n",
        "# Treatment: Clip Sales outliers at 99th percentile (to handle extreme high values)\n",
        "sales_99th = np.percentile(df['Sales'], 99)\n",
        "df['Sales'] = df['Sales'].clip(upper=sales_99th)\n",
        "\n",
        "# Treatment: Winsorize CompetitionDistance (replace outliers with 95th/5th percentiles)\n",
        "from scipy.stats import mstats\n",
        "df['CompetitionDistance'] = mstats.winsorize(df['CompetitionDistance'], limits=[0.05, 0.05])\n",
        "\n",
        "# Re-visualize after treatment\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=df['Sales'])\n",
        "plt.title('Boxplot of Sales (After Clipping Outliers)')\n",
        "plt.show()\n",
        "\n",
        "# Similarly, check CompetitionDistance (a key feature)\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=df['CompetitionDistance'])\n",
        "plt.title('Boxplot of CompetitionDistance (After Clipping Outliers)')\n",
        "plt.show()\n",
        "print(\"Outliers handled: Sales capped at 99th percentile, CompetitionDistance winsorized.\")"
      ],
      "metadata": {
        "id": "M6w2CzZf04JK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all outlier treatment techniques have you used and why did you use those techniques?"
      ],
      "metadata": {
        "id": "578E2V7j08f6"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Clipping for Sales: Caps extreme values (e.g., rare high-sales days) to the 99th percentile, preventing model skew while retaining all rows.\n",
        "- Winsorizing for CompetitionDistance: Replaces top/bottom 5% with percentile values, as distance can have natural extremes but shouldn't dominate.\n",
        "These techniques were chosen over removal (e.g., IQR method) to avoid losing time-series continuity and valid business events like promo spikes."
      ],
      "metadata": {
        "id": "uGZz5OrT1HH-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3. Categorical Encoding"
      ],
      "metadata": {
        "id": "89xtkJwZ18nB"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "21JmIYMG2hEo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### What all categorical encoding techniques have you used & why did you use those techniques?"
      ],
      "metadata": {
        "id": "67NQN5KX2AMe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "UDaue5h32n_G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Textual Data Preprocessing\n",
        "(It's mandatory for textual dataset i.e., NLP, Sentiment Analysis, Text Clustering etc.)"
      ],
      "metadata": {
        "id": "Iwf50b-R2tYG"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "D_9pD4yTP8s8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Expand Contraction"
      ],
      "metadata": {
        "id": "GMQiZwjn3iu7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Expand Contraction"
      ],
      "metadata": {
        "id": "PTouz10C3oNN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Lower Casing"
      ],
      "metadata": {
        "id": "WVIkgGqN3qsr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lower Casing"
      ],
      "metadata": {
        "id": "88JnJ1jN3w7j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Removing Punctuations"
      ],
      "metadata": {
        "id": "XkPnILGE3zoT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Punctuations"
      ],
      "metadata": {
        "id": "vqbBqNaA33c0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 4. Removing URLs & Removing words and digits contain digits."
      ],
      "metadata": {
        "id": "Hlsf0x5436Go"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove URLs & Remove words and digits contain digits"
      ],
      "metadata": {
        "id": "2sxKgKxu4Ip3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 5. Removing Stopwords & Removing White spaces"
      ],
      "metadata": {
        "id": "mT9DMSJo4nBL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove Stopwords"
      ],
      "metadata": {
        "id": "T2LSJh154s8W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove White spaces"
      ],
      "metadata": {
        "id": "EgLJGffy4vm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 6. Rephrase Text"
      ],
      "metadata": {
        "id": "c49ITxTc407N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rephrase Text"
      ],
      "metadata": {
        "id": "foqY80Qu48N2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 7. Tokenization"
      ],
      "metadata": {
        "id": "OeJFEK0N496M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tokenization"
      ],
      "metadata": {
        "id": "ijx1rUOS5CUU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 8. Text Normalization"
      ],
      "metadata": {
        "id": "9ExmJH0g5HBk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Normalizing Text (i.e., Stemming, Lemmatization etc.)"
      ],
      "metadata": {
        "id": "AIJ1a-Zc5PY8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text normalization technique have you used and why?"
      ],
      "metadata": {
        "id": "cJNqERVU536h"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Z9jKVxE06BC1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 9. Part of speech tagging"
      ],
      "metadata": {
        "id": "k5UmGsbsOxih"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# POS Taging"
      ],
      "metadata": {
        "id": "btT3ZJBAO6Ik"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 10. Text Vectorization"
      ],
      "metadata": {
        "id": "T0VqWOYE6DLQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorizing Text"
      ],
      "metadata": {
        "id": "yBRtdhth6JDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which text vectorization technique have you used and why?"
      ],
      "metadata": {
        "id": "qBMux9mC6MCf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "su2EnbCh6UKQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4. Feature Manipulation & Selection"
      ],
      "metadata": {
        "id": "-oLEiFgy-5Pf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Feature Manipulation"
      ],
      "metadata": {
        "id": "C74aWNz2AliB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Manipulate Features to minimize feature correlation and create new features"
      ],
      "metadata": {
        "id": "h1qC4yhBApWC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Feature Selection"
      ],
      "metadata": {
        "id": "2DejudWSA-a0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Select your features wisely to avoid overfitting"
      ],
      "metadata": {
        "id": "YLhe8UmaBCEE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What all feature selection methods have you used  and why?"
      ],
      "metadata": {
        "id": "pEMng2IbBLp7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "rb2Lh6Z8BgGs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which all features you found important and why?"
      ],
      "metadata": {
        "id": "rAdphbQ9Bhjc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "fGgaEstsBnaf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 5. Data Transformation"
      ],
      "metadata": {
        "id": "TNVZ9zx19K6k"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Do you think that your data needs to be transformed? If yes, which transformation have you used. Explain Why?"
      ],
      "metadata": {
        "id": "nqoHp30x9hH9"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "I6quWQ1T9rtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 6. Data Scaling"
      ],
      "metadata": {
        "id": "rMDnDkt2B6du"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Scaling your data"
      ],
      "metadata": {
        "id": "dL9LWpySC6x_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which method have you used to scale you data and why?"
      ],
      "metadata": {
        "id": "yiiVWRdJDDil"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 7. Dimesionality Reduction"
      ],
      "metadata": {
        "id": "1UUpS68QDMuG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think that dimensionality reduction is needed? Explain Why?"
      ],
      "metadata": {
        "id": "kexQrXU-DjzY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GGRlBsSGDtTQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# DImensionality Reduction (If needed)"
      ],
      "metadata": {
        "id": "kQfvxBBHDvCa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which dimensionality reduction technique have you used and why? (If dimensionality reduction done on dataset.)"
      ],
      "metadata": {
        "id": "T5CmagL3EC8N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "ZKr75IDuEM7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 8. Data Splitting"
      ],
      "metadata": {
        "id": "BhH2vgX9EjGr"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0CTyd2UwEyNM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What data splitting ratio have you used and why?"
      ],
      "metadata": {
        "id": "qjKvONjwE8ra"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "Y2lJ8cobFDb_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 9. Handling Imbalanced Dataset"
      ],
      "metadata": {
        "id": "P1XJ9OREExlT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Do you think the dataset is imbalanced? Explain Why."
      ],
      "metadata": {
        "id": "VFOzZv6IFROw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "GeKDIv7pFgcC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Handling Imbalanced Dataset (If needed)"
      ],
      "metadata": {
        "id": "nQsRhhZLFiDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### What technique did you use to handle the imbalance dataset and why? (If needed to be balanced)"
      ],
      "metadata": {
        "id": "TIqpNgepFxVj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "qbet1HwdGDTz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***7. ML Model Implementation***"
      ],
      "metadata": {
        "id": "VfCC591jGiD4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to evaluate\n",
        "def evaluate(y_true, y_pred, model_name):\n",
        "    y_pred = np.expm1(y_pred)  # Inverse log\n",
        "    y_true = np.expm1(y_true)\n",
        "    y_pred = np.clip(y_pred, 0, None)\n",
        "    rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
        "    r2 = r2_score(y_true, y_pred)\n",
        "    rmspe = np.sqrt(np.mean(((y_true - y_pred) / y_true) ** 2)) if np.all(y_true != 0) else np.nan\n",
        "    print(f\"\\n{model_name} Performance:\")\n",
        "    print(f\"RMSE : {rmse:.2f}\")\n",
        "    print(f\"R2   : {r2:.4f}\")\n",
        "    print(f\"RMSPE: {rmspe:.4f}\")\n",
        "    return rmse, r2, rmspe"
      ],
      "metadata": {
        "id": "5xxBXCi4pu2H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 1"
      ],
      "metadata": {
        "id": "OB4l2ZhMeS1U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model 1: Linear Regression\n",
        "print(\"\\nTraining Linear Regression...\")\n",
        "X_train_sm = sm.add_constant(X_train.toarray() if hasattr(X_train, 'toarray') else X_train, has_constant='add')\n",
        "X_test_sm = sm.add_constant(X_test.toarray() if hasattr(X_test, 'toarray') else X_test, has_constant='add')\n",
        "lr_model = sm.OLS(y_train, X_train_sm).fit()\n",
        "y_pred_lr = lr_model.predict(X_test_sm)\n",
        "evaluate(y_test, y_pred_lr, \"Linear Regression\")"
      ],
      "metadata": {
        "id": "7ebyywQieS1U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "JWYfwnehpsJ1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We used Ordinary Least Squares (OLS) Linear Regression from the statsmodels library as our first baseline model.\n",
        "How Linear Regression Works in this context\n",
        "Linear Regression assumes a linear relationship between the independent features (Promo, StoreType, CompetitionDistance, DayOfWeek, etc.) and the target variable (Sales). It tries to find the best-fitting straight line (in multiple dimensions) by minimizing the sum of squared residuals.\n",
        "\n",
        "**Business Interpretation & Limitations**\n",
        "\n",
        "* RMSE = 1988.91 €:\n",
        "This means the typical prediction error is about €1,989 per day per store. For high-volume stores (sales > €10,000), this might be acceptable (~20% error), but for smaller stores or slow days, it becomes a large relative mistake.\n",
        "\n",
        "* R² = 0.5784:\n",
        "Only ~58% of the variation in sales is explained by the linear combination of features. This indicates that important non-linear patterns (e.g. interaction between Promo + Weekend, or Promo + StoreType) and seasonal effects are not being captured well by a simple linear model.\n",
        "\n",
        "* RMSPE = 26.55%:\n",
        "The percentage-based error is quite high. This is especially problematic in retail forecasting because:\n",
        "Large % errors on low-sales days → risk of severe overstocking or stockouts\n",
        "Hurts smaller stores disproportionately\n",
        "Makes the model less trustworthy for chain-wide planning\n",
        "\n",
        "\n",
        "**Conclusion about Linear Regression:**\n",
        "\n",
        "Linear Regression serves as a good interpretable baseline, but it clearly\n",
        "underperforms for this dataset. Sales have strong non-linearities, categorical interactions, and time-based patterns that a linear model cannot capture effectively. This is why tree-based models (Random Forest, XGBoost, LightGBM) usually perform significantly better on the Rossmann dataset.\n",
        "You can paste the table and explanation directly into the markdown cell under “1. Explain the ML Model used and it's performance using Evaluation metric Score Chart.”"
      ],
      "metadata": {
        "id": "XWT0syJbYUCd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "4qY1EAkEfxKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "Dy61ujd6fxKe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "PiV4Ypx8fxKe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "negyGRa7fxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "TfvqoZmBfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "OaLui8CcfxKf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 2"
      ],
      "metadata": {
        "id": "dJ2tPlVmpsJ0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "# Model 2: Random Forest\n",
        "print(\"\\nTraining Random Forest...\")\n",
        "rf_model = RandomForestRegressor(n_estimators=50, random_state=42, n_jobs=-1)\n",
        "rf_model.fit(X_train, y_train)\n",
        "y_pred_rf = rf_model.predict(X_test)\n",
        "evaluate(y_test, y_pred_rf, \"Random Forest\")"
      ],
      "metadata": {
        "id": "yEl-hgQWpsJ1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "-jK_YjpMpsJ2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 1 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Define parameter distribution for RandomizedSearchCV\n",
        "param_dist = {\n",
        "    'n_estimators': randint(50, 200),  # Number of trees in the forest\n",
        "    'max_features': ['auto', 'sqrt', 'log2'], # Number of features to consider when looking for the best split\n",
        "    'max_depth': randint(10, 50),       # Maximum number of levels in tree\n",
        "    'min_samples_split': randint(2, 10), # Minimum number of samples required to split an internal node\n",
        "    'min_samples_leaf': randint(1, 5),   # Minimum number of samples required to be at a leaf node\n",
        "    'bootstrap': [True, False]          # Method for sampling data points (with or without replacement)\n",
        "}\n",
        "\n",
        "# Initialize a Random Forest Regressor\n",
        "rf_base = RandomForestRegressor(random_state=42, n_jobs=-1)\n",
        "\n",
        "# Initialize RandomizedSearchCV\n",
        "print(\"\\nPerforming RandomizedSearchCV for Random Forest...\")\n",
        "random_search_rf = RandomizedSearchCV(\n",
        "    estimator=rf_base,\n",
        "    param_distributions=param_dist,\n",
        "    n_iter=10,  # Number of parameter settings that are sampled. Trade-off between accuracy and runtime.\n",
        "    cv=3,       # 3-fold cross-validation\n",
        "    verbose=2,  # Controls the verbosity: the higher, the more messages.\n",
        "    random_state=42,\n",
        "    n_jobs=-1   # Use all available cores\n",
        ")\n",
        "\n",
        "# Fit the Algorithm\n",
        "random_search_rf.fit(X_train, y_train)\n",
        "\n",
        "# Get the best estimator\n",
        "best_rf_model = random_search_rf.best_estimator_\n",
        "\n",
        "print(f\"\\nBest parameters found: {random_search_rf.best_params_}\")\n",
        "\n",
        "# Predict on the model\n",
        "y_pred_rf_tuned = best_rf_model.predict(X_test)\n",
        "\n",
        "# Evaluate the tuned model\n",
        "rmse_tuned, r2_tuned, rmspe_tuned = evaluate(y_test, y_pred_rf_tuned, \"Tuned Random Forest\")\n",
        "\n",
        "# Store initial and tuned metrics for comparison\n",
        "initial_rf_rmse = np.float64(935.8394836324361)\n",
        "initial_rf_r2 = 0.9066594748341168\n",
        "initial_rf_rmspe = np.float64(0.14495757843517365)\n",
        "\n",
        "print(\"\\n--- Performance Comparison (Random Forest) ---\")\n",
        "print(f\"Initial Random Forest RMSE: {initial_rf_rmse:.2f}\")\n",
        "print(f\"Tuned Random Forest RMSE:   {rmse_tuned:.2f}\\n\")\n",
        "print(f\"Initial Random Forest R2:   {initial_rf_r2:.4f}\")\n",
        "print(f\"Tuned Random Forest R2:     {r2_tuned:.4f}\\n\")\n",
        "print(f\"Initial Random Forest RMSPE: {initial_rf_rmspe:.4f}\")\n",
        "print(f\"Tuned Random Forest RMSPE:   {rmspe_tuned:.4f}\")"
      ],
      "metadata": {
        "id": "Dn0EOfS6psJ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "HAih1iBOpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "9kBgjYcdpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "zVGeBEFhpsJ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "74yRdG6UpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 3. Explain each evaluation metric's indication towards business and the business impact pf the ML model used."
      ],
      "metadata": {
        "id": "bmKjuQ-FpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Model Performance Summary (Random Forest – n_estimators=50)**\n",
        "\n",
        "| Metric   | Value       | Business Indication                                                                 |\n",
        "|----------|-------------|--------------------------------------------------------------------------------------|\n",
        "| RMSE     | 935.84 €    | Predictions are off by ~ €936 on average — much better than linear regression (~€1,989) |\n",
        "| R²       | 0.9067      | Model explains ~ 90.7% of the variance in sales — very strong explanatory power       |\n",
        "| RMSPE    | 14.50%      | Average percentage error ~14.5% — significantly improved, better on low-sales days  |\n",
        "\n",
        "#### 1. RMSE (Root Mean Squared Error) = 935.84 €\n",
        "- **Business Indication**:  \n",
        "  The model’s average prediction error is only ~€936 per day per store.  \n",
        "  Compared to Linear Regression (RMSE ~€1,989), this is roughly **53% lower error** → much tighter forecasts.\n",
        "- **Business Impact**:  \n",
        "  - Reduces costly overstocking and stockouts  \n",
        "  - Helps optimize daily inventory orders more accurately  \n",
        "  - For high-volume stores, €936 error is often <10% of daily sales → acceptable for operational planning\n",
        "\n",
        "#### 2. R² (Coefficient of Determination) = 0.9067 (90.67%)\n",
        "- **Business Indication**:  \n",
        "  Random Forest captures ~90.7% of the patterns/variability in daily sales.  \n",
        "  This means most important drivers (Promo, StoreType, DayOfWeek, CompetitionDistance, seasonality, etc.) are being well understood by the model.\n",
        "- **Business Impact**:  \n",
        "  - High trust in the model → store managers can confidently use forecasts for staffing, promotion planning, and ordering  \n",
        "  - Enables better explanation of “why sales change” (via feature importance)  \n",
        "  - Supports data-driven decisions across 1,115 stores\n",
        "\n",
        "#### 3. RMSPE (Root Mean Squared Percentage Error) = 14.50%\n",
        "- **Business Indication**:  \n",
        "  The average percentage error is only ~14.5% — much better than Linear Regression (~26.6%).  \n",
        "  This shows the model performs more consistently across small and large stores, and during low-sales periods (weekends, holidays).\n",
        "- **Business Impact**:  \n",
        "  - Fairer and more equitable forecasting → smaller stores are not disproportionately penalized  \n",
        "  - Lower risk of large relative errors during slow periods (critical for avoiding waste)  \n",
        "  - Better aligns with real retail KPI: percentage-based accuracy matters more than absolute euros when store sizes vary widely\n",
        "\n",
        "**Overall Business Impact of Random Forest Model**\n",
        "\n",
        "Random Forest significantly outperforms the linear baseline and delivers strong, practical forecasting power:\n",
        "\n",
        "- **Improved Accuracy** → ~53% reduction in average error (RMSE) compared to Linear Regression  \n",
        "- **High Explainability** → ~91% of sales variation captured → managers understand what really drives sales  \n",
        "- **Balanced Performance** → RMSPE of 14.5% means reliable forecasts even on low-volume days  \n",
        "- **Operational Benefits**:  \n",
        "  - Better inventory planning → reduced holding costs & waste  \n",
        "  - Smarter promotion decisions → higher ROI on promo campaigns  \n",
        "  - More accurate staffing forecasts → optimized labor costs  \n",
        "  - Scalable across thousands of stores → supports chain-wide strategy\n",
        "\n",
        "**Conclusion**  \n",
        "Random Forest is already a very strong model for this project — offering excellent accuracy, good generalization, and reasonable interpretability through feature importance. It provides clear business value by reducing forecasting uncertainty and enabling more precise, profit-oriented decisions compared to simpler models.\n",
        "You can paste this directly into the cell.\n",
        "If your notebook also has an XGBoost / LightGBM model (Model 3), let me know the performance numbers (RMSE, R², RMSPE) and I can prepare a similar high-quality explanation for that one too.\n",
        "Good luck with your submission!22.5sFast"
      ],
      "metadata": {
        "id": "BDKtOrBQpsJ3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ML Model - 3"
      ],
      "metadata": {
        "id": "Fze-IPXLpx6K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation\n",
        "\n",
        "# Model 3: XGBoost\n",
        "print(\"\\nTraining XGBoost...\")\n",
        "xgb_model = xgb.XGBRegressor(objective='reg:squarederror', n_estimators=100, random_state=42)\n",
        "xgb_model.fit(X_train, y_train)\n",
        "y_pred_xgb = xgb_model.predict(X_test)\n",
        "evaluate(y_test, y_pred_xgb, \"XGBoost\")"
      ],
      "metadata": {
        "id": "FFrSXAtrpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 1. Explain the ML Model used and it's performance using Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "7AN1z2sKpx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing evaluation Metric Score chart\n",
        "\n"
      ],
      "metadata": {
        "id": "xIY4lxxGpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 2. Cross- Validation & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "9PIHJqyupx6M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ML Model - 3 Implementation with hyperparameter optimization techniques (i.e., GridSearch CV, RandomSearch CV, Bayesian Optimization etc.)\n",
        "\n",
        "# Fit the Algorithm\n",
        "\n",
        "# Predict on the model"
      ],
      "metadata": {
        "id": "eSVXuaSKpx6M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Which hyperparameter optimization technique have you used and why?"
      ],
      "metadata": {
        "id": "_-qAgymDpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "lQMffxkwpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Have you seen any improvement? Note down the improvement with updates Evaluation metric Score Chart."
      ],
      "metadata": {
        "id": "Z-hykwinpx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Answer Here."
      ],
      "metadata": {
        "id": "MzVzZC6opx6N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Which Evaluation metrics did you consider for a positive business impact and why?"
      ],
      "metadata": {
        "id": "h_CCil-SKHpo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "I considered RMSE (Root Mean Squared Error) and RMSPE (Root Mean Squared Percentage Error) as the primary evaluation metrics.\n",
        "\n",
        "RMSE measures the average magnitude of prediction errors in the same unit as sales (euros). It is critical for retail forecasting because it directly reflects how much revenue might be over- or under-estimated on average. Lower RMSE means better inventory planning, reduced stock-outs or overstock, and improved cash flow — all leading to positive business impact.\n",
        "RMSPE was also used because it expresses error as a percentage, giving more weight to accurate predictions on low-sales days (e.g., holidays or slow periods). This prevents large percentage errors on smaller stores/days, which is important for fair performance across all 1,115 stores and aligns closely with real-world business needs.\n",
        "\n",
        "Additionally, R² was monitored to understand how much variance in sales the model explains.\n",
        "From the XGBoost model results:\n",
        "\n",
        "RMSE: 1056.64\n",
        "R²: 0.952\n",
        "RMSPE: 0.1632\n",
        "\n",
        "These strong scores indicate high accuracy and reliable forecasts for operational decision-making."
      ],
      "metadata": {
        "id": "jHVz9hHDKFms"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Which ML model did you choose from the above created models as your final prediction model and why?"
      ],
      "metadata": {
        "id": "cBFFvTBNJzUa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Best Performing Model\n",
        "\n",
        "The **Tuned Random Forest** model is the best performing model in this analysis, demonstrating the **lowest RMSE** and the **highest R² score**. While the initial Random Forest was already strong, tuning allowed for slight improvements, making it the most accurate predictor.\n",
        "\n",
        "## Business Implications\n",
        "\n",
        "1. **Improved Sales Forecasting Accuracy**  \n",
        "   The Tuned Random Forest model's **RMSE of approximately 925 euros** means that, on average, the model's predictions are off by about 925 euros. An **R² of ~0.9087** indicates that over 90% of the variance in sales can be explained by the model. The **RMSPE of ~0.1452** means that the average percentage error in sales predictions is about 14.5%.  \n",
        "   This level of accuracy is a significant improvement over a simple linear model and can lead to several positive business impacts.\n",
        "\n",
        "2. **Inventory Optimization**  \n",
        "   More accurate sales forecasts allow store managers to optimize inventory levels. This can reduce:\n",
        "   - Overstocking (minimizing waste, spoilage for perishable goods, and storage costs)  \n",
        "   - Understocking (preventing lost sales due to out-of-stock items)  \n",
        "   This directly impacts **profitability** and **customer satisfaction**.\n",
        "\n",
        "3. **Staffing Efficiency**  \n",
        "   Predicting daily sales helps in planning optimal staffing levels.  \n",
        "   - On days with higher predicted sales → more staff can be scheduled to manage customer traffic and maintain service quality.  \n",
        "   - During low-sales periods → staffing can be adjusted to reduce labor costs without compromising service.\n",
        "\n",
        "4. **Effective Promotion Planning**  \n",
        "   The model can help in understanding the impact of promotions and planning future promotional activities more effectively. By accurately forecasting sales **with and without promotions**, Rossmann can better assess the **ROI** of their marketing efforts.\n",
        "\n",
        "5. **Strategic Decision Making**  \n",
        "   Insights from the model can aid in broader strategic decisions, such as:  \n",
        "   - Store expansion  \n",
        "   - Assortment planning for different store types  \n",
        "   - Identifying underperforming stores that might need interventions  \n",
        "   For example, if the model consistently underpredicts sales for certain stores, it might indicate unmet demand or opportunities for growth.\n",
        "\n",
        "6. **Revenue Optimization**  \n",
        "   By minimizing forecasting errors, the business can make better-informed decisions across various operational aspects, ultimately leading to **increased revenue** and **reduced operational costs**.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The **Tuned Random Forest** model provides a robust and reliable tool for Rossmann to forecast sales, which can significantly enhance **operational efficiency**, **customer satisfaction**, and **overall profitability**."
      ],
      "metadata": {
        "id": "6ksF5Q1LKTVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Sales Preiction usind different models\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# 1. Generate a list of 5 random indices from the y_test Series\n",
        "np.random.seed(42) # for reproducibility\n",
        "random_indices = np.random.choice(len(y_test), 5, replace=False)\n",
        "\n",
        "# Get actual sales values (inverse log-transformed)\n",
        "actual_sales = np.expm1(y_test.iloc[random_indices])\n",
        "\n",
        "# Get predicted sales values for each model (inverse log-transformed)\n",
        "# Since y_pred_lr, y_pred_rf, y_pred_xgb are predictions on X_test, their indices are aligned with y_test\n",
        "predicted_lr = np.expm1(y_pred_lr[random_indices])\n",
        "predicted_rf = np.expm1(y_pred_rf[random_indices])\n",
        "predicted_xgb = np.expm1(y_pred_xgb[random_indices])\n",
        "\n",
        "# 2. Create a Pandas DataFrame to store the comparison results.\n",
        "comparison_df = pd.DataFrame({\n",
        "    'Actual Sales': actual_sales,\n",
        "    'Predicted LR': predicted_lr,\n",
        "    'Predicted RF': predicted_rf,\n",
        "    'Predicted XGB': predicted_xgb\n",
        "})\n",
        "\n",
        "# Round to 2 decimal places for better readability\n",
        "comparison_df = comparison_df.round(2)\n",
        "\n",
        "# 5. Print the created DataFrame to display the actual vs. predicted sales for the selected samples.\n",
        "print(\"\\n--- Sales Prediction Comparison (Random 5 Samples) ---\")\n",
        "print(comparison_df)\n"
      ],
      "metadata": {
        "id": "PeiNy6jlhqsV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ***8.*** ***Future Work (Optional)***"
      ],
      "metadata": {
        "id": "EyNgTHvd2WFk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 1. Save the best performing ml model in a pickle file or joblib file format for deployment process.\n"
      ],
      "metadata": {
        "id": "KH5McJBi2d8v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll save the trained Linear Regression model using joblib for easy deployment.\n",
        "import joblib\n",
        "\n",
        "# Save the model\n",
        "joblib.dump(rf_model, 'rossmann_sales_model(rf_model).joblib')\n",
        "print(\"Model saved as rossmann_sales_model(rf_model).joblib\")\n"
      ],
      "metadata": {
        "id": "bQIANRl32f4J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 2. Again Load the saved model file and try to predict unseen data for a sanity check.\n"
      ],
      "metadata": {
        "id": "iW_Lq9qf2h6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the File and predict unseen data.\n",
        "\n",
        "# Load the model\n",
        "loaded_model = joblib.load('rossmann_sales_model(rf_model).joblib')\n",
        "\n",
        "# Sample unseen data (mimic a new row; adjust based on your preprocessor)\n",
        "# Assume preprocessed input (use your preprocessor to transform new data in production)\n",
        "sample_data = X_test[0:1]  # First row from test set as 'unseen'\n",
        "\n",
        "# Predict\n",
        "prediction = loaded_model.predict(sample_data)\n",
        "print(f\"Predicted Sales for sample data: {prediction[0]:.2f}\")\n",
        "\n",
        "# Sanity check: Compare to actual if available\n",
        "actual = y_test.iloc[0]\n",
        "print(f\"Actual Sales: {actual:.2f}\")\n",
        "print(f\"Prediction Error: {abs(prediction[0] - actual):.2f}\")"
      ],
      "metadata": {
        "id": "oEXk9ydD2nVC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "id": "gj25o2tbpnG6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Congrats! Your model is successfully created and ready for deployment on a live server for a real user interaction !!!***"
      ],
      "metadata": {
        "id": "-Kee-DAl2viO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Conclusion**"
      ],
      "metadata": {
        "id": "gCX9965dhzqZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The **Rossmann Retail Sales Prediction** project successfully developed a robust machine learning pipeline to forecast daily sales across 1,115 stores, addressing one of the core challenges faced by retail managers: accurate demand forecasting up to six weeks in advance.\n",
        "\n",
        "Through comprehensive **Exploratory Data Analysis**, thoughtful **feature engineering** (competition months open, promo intervals, date-based seasonality features), careful data cleaning, and systematic model comparison, we evaluated multiple approaches:\n",
        "\n",
        "- Linear Regression served as an interpretable baseline but showed clear limitations (RMSE ~1989 €, R² ~0.58, RMSPE ~26.5%).\n",
        "- Random Forest delivered a strong improvement (RMSE ~936 €, R² ~0.91, RMSPE ~14.5%).\n",
        "- The **Tuned Random Forest** (or XGBoost in some runs) emerged as the best-performing model, achieving the lowest errors and highest explanatory power (RMSE ≈ 925–1057 €, R² ≈ 0.91–0.95, RMSPE ≈ 14.5–16.3%).\n",
        "\n",
        "**Key business takeaways**:\n",
        "\n",
        "- Promotions remain the single most powerful driver of sales — the model clearly quantifies their massive positive impact.\n",
        "- Accurate forecasts enable **better inventory management**, significantly reducing overstock (waste & storage costs) and understock (lost sales).\n",
        "- Improved staffing alignment, more strategic promotion planning, and data-driven assortment decisions become possible.\n",
        "- Percentage-based errors (RMSPE) were minimized, ensuring fairness across small and large stores and during low-traffic periods.\n",
        "- Overall, deployment of this model has the potential to deliver **measurable improvements in operational efficiency, revenue optimization, and customer satisfaction** — translating into substantial cost savings and profit uplift for Rossmann across its European network.\n",
        "\n",
        "While the current solution is already production-viable, future enhancements could include:\n",
        "- Incorporation of external data (weather, local events, economic indicators)\n",
        "- Time-series specific models (Prophet, LSTM) or hybrid approaches\n",
        "- Real-time retraining pipelines\n",
        "- Deployment as an API or dashboard for store managers\n",
        "\n",
        "In summary, this project demonstrates the transformative power of machine learning in retail — turning complex, noisy historical data into actionable, high-accuracy forecasts that directly support smarter, more profitable business decisions.\n",
        "\n",
        "**Thank you for exploring this Rossmann Sales Prediction Capstone Project!**  "
      ],
      "metadata": {
        "id": "Fjb1IsQkh3yE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ***Hurrah! You have successfully completed your Machine Learning Capstone Project !!!***"
      ],
      "metadata": {
        "id": "gIfDvo9L0UH2"
      }
    }
  ]
}